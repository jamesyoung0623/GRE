# GRE

## Environment setup
    conda create -n gre python=3.9
    conda activate gre
    pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 -f https://download.pytorch.org/whl/torch_stable.html
    pip install -r requirements.txt

## Download pre-trained models
Download the [data](https://osf.io/cpgjh/?view_only=37ddf8919fe14f9b99b684aa9416585a) folder as a zip file and unzip.

## Download dataset
Download the [dataset](https://osf.io/cpgjh/?view_only=37ddf8919fe14f9b99b684aa9416585a), unzip the files, and place it to the same path as well. Put the images into the `test` folder if they are split into `test1.zip` and `test2.zip`. Run `link.sh` to create soft links for the dataset. 

## Testing
Make sure the configuration in `test.sh` is correct and run 

    sh test.sh

## Training
Make sure the configuration in `train.sh` is correct and run 

    sh train.sh

## Acknowledgement
Our code is developed based on [DIRE](https://github.com/ZhendongWang6/DIRE). The dataset is generated by [3D Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting), [mip-splatting](https://github.com/autonomousvision/mip-splatting), [Compact-3DGS](https://github.com/maincold2/Compact-3DGS), [ges-splatting](https://github.com/ajhamdi/ges-splatting), [Scaffold-GS](https://github.com/city-super/Scaffold-GS), and [GS-IR](https://github.com/lzhnb/GS-IR).